# TwitterAPI- WeRateDogs

My second project in **Udacity Data Analyst Nanodegree** program where I extracted data from Twitter API to perform data analysis.

## Introduction
Project objectives: Perform data wrangling (gathering, assessing and cleaning) on provided three sources of data. 
Store, analyze, and visualize the wrangled data. Reporting on;
 1) data wrangling efforts and 
 2) data analyses and visualizations
 
### Language, Packages and Libraries
The project is using Jupyter notebook with Python 3.9. The packages include numpy, pandas, requests, tweepy, json, re, matplotlib.pyplot and seaborn.

### Metadata
The definition of tweet data can be found on the twitter website

#### Image prediction is generated by neural network. The definitions of the variables are in the following.
## Variable Name and	Definition of the features are as follows;

 **tweet_id**:	the last part of the tweet URL after "status/"
 
 **p1**:	the algorithm's #1 prediction for the image in the tweet
 
 **p1_conf**:	how confident the algorithm is in its #1 prediction
 
 **p1_dog**:	whether or not the #1 prediction is a breed of dog
 
 **p2**:	the algorithm's #2 prediction for the image in the tweet
 
 **p2_conf**:	how confident the algorithm is in its #2 prediction
 
 **p2_dog**:	whether or not the #2 prediction is a breed of dog
 
 **p3**:	the algorithm's #3 prediction for the image in the tweet
 
 **p3_conf**:	how confident the algorithm is in its #3 prediction
 
 **p3_dog**:	whether or not the #3 prediction is a breed of dog

## Datasets

1.**twitter_archive_enhanced.csv**: file as given

2.**image_predictions.tsv**: file downloaded programmatically

3.**tweet_json.txt**: file constructed via API

4.**twitter_archive_master.csv**: combined and cleaned data

5.**image_predictions_tp.csv**: cleaned data

clean_df includes cleaned data, twitter_archive_master.csv and image_predictions_tp.csv
